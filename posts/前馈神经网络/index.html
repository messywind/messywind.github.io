<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-cn">
  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>前馈神经网络 - 凌乱之风的博客</title><meta name="author" content="凌乱之风">
<meta name="description" content="模型 模型由多层感知机构成，每层有若干个神经元，第一层是输入层，最后一层是输出层。如下图所示
"><meta name="keywords" content='神经网络'>
  <meta itemprop="name" content="前馈神经网络">
  <meta itemprop="description" content="模型 模型由多层感知机构成，每层有若干个神经元，第一层是输入层，最后一层是输出层。如下图所示">
  <meta itemprop="datePublished" content="2024-11-10T14:07:00+00:00">
  <meta itemprop="dateModified" content="2024-11-21T09:24:39+00:00">
  <meta itemprop="wordCount" content="1914">
  <meta itemprop="keywords" content="神经网络"><meta property="og:url" content="https://blog.messywind.top/posts/%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
  <meta property="og:site_name" content="凌乱之风的博客">
  <meta property="og:title" content="前馈神经网络">
  <meta property="og:description" content="模型 模型由多层感知机构成，每层有若干个神经元，第一层是输入层，最后一层是输出层。如下图所示">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-11-10T14:07:00+00:00">
    <meta property="article:modified_time" content="2024-11-21T09:24:39+00:00">
    <meta property="article:tag" content="神经网络">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="前馈神经网络">
  <meta name="twitter:description" content="模型 模型由多层感知机构成，每层有若干个神经元，第一层是输入层，最后一层是输出层。如下图所示">
<meta name="application-name" content="凌乱之风的博客">
<meta name="apple-mobile-web-app-title" content="凌乱之风的博客"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="icon" href="images/favicon.ico"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="canonical" type="text/html" href="https://blog.messywind.top/posts/%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="前馈神经网络 - 凌乱之风的博客" /><link rel="prev" type="text/html" href="https://blog.messywind.top/posts/%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F-s14-%E6%80%BB%E5%86%B3%E8%B5%9B/" title="2024 英雄联盟 S14 全球总决赛 观赛感悟" /><link rel="next" type="text/html" href="https://blog.messywind.top/posts/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" title="支持向量机 (SVM)" /><link rel="alternate" type="text/markdown" href="https://blog.messywind.top/posts/%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.md" title="前馈神经网络 - 凌乱之风的博客"><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="/lib/fontawesome-free/all.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/lib/animate/animate.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "前馈神经网络",
    "inLanguage": "zh-cn",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https:\/\/blog.messywind.top\/posts\/%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\/"
    },"genre": "posts","keywords": "神经网络","wordcount":  1914 ,
    "url": "https:\/\/blog.messywind.top\/posts\/%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\/","datePublished": "2024-11-10T14:07:00+00:00","dateModified": "2024-11-21T09:24:39+00:00","publisher": {
      "@type": "Organization",
      "name": ""},"author": {
        "@type": "Person",
        "name": "凌乱之风"
      },"description": ""
  }
  </script><script src="/js/head/color-scheme.min.js"></script></head>
  <body data-header-desktop="sticky" data-header-mobile="auto"><div class="wrapper" data-page-style="normal"><header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper">
    <div class="header-title">
      <a href="/" title="凌乱之风的博客"><img loading="lazy" src="/images/favicon.ico" alt="凌乱之风的博客" data-title="凌乱之风的博客" width="26" height="26" class="logo" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/><span class="header-title-text">凌乱之风的博客</span></a><span class="header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a class="menu-link" href="/archives/"><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 档案</a></li><li class="menu-item">
              <a class="menu-link" href="/categories/"><i class="fa-solid fa-folder-tree fa-fw fa-sm" aria-hidden="true"></i> 目录</a></li><li class="menu-item">
              <a class="menu-link" href="/tags/"><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li class="menu-item">
              <a class="menu-link" href="/friends/"><i class="fa-solid fa-link fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id="search-desktop">
            <input type="text" placeholder="搜索文章标题或内容……" id="search-input-desktop">
            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
              <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
            </a>
            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
              <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
            </a>
            <span class="search-button search-loading" id="search-loading-desktop">
              <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
            </span>
          </li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li></ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/" title="凌乱之风的博客"><img loading="lazy" src="/images/favicon.ico" alt="凌乱之风的博客" data-title="凌乱之风的博客" width="26" height="26" class="logo" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/><span class="header-title-text">凌乱之风的博客</span></a><span class="header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="search-wrapper">
            <div class="search mobile" id="search-mobile">
              <input type="text" placeholder="搜索文章标题或内容……" id="search-input-mobile">
              <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
              </a>
              <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
              </a>
              <span class="search-button search-loading" id="search-loading-mobile">
                <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
              </span>
            </div>
            <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
              取消
            </a>
          </li><li class="menu-item"><a class="menu-link" href="/archives/"><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 档案</a></li><li class="menu-item"><a class="menu-link" href="/categories/"><i class="fa-solid fa-folder-tree fa-fw fa-sm" aria-hidden="true"></i> 目录</a></li><li class="menu-item"><a class="menu-link" href="/tags/"><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li class="menu-item"><a class="menu-link" href="/friends/"><i class="fa-solid fa-link fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li class="menu-item menu-system">
          <span class="menu-system-item theme-switch" title="切换主题"><i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i></span></li>
      </ul>
    </nav>
  </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
  </div>
  <div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
  </div><main class="container"><aside class="aside-collection animate__animated animate__fadeIn animate__faster" aria-label="合集"></aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX"><span>前馈神经网络</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><a href="https://github.com/messywind" title="作者"target="_blank" rel="external nofollow noopener noreferrer author" class="author"><img loading="lazy" src="/images/favicon.ico" alt="凌乱之风" data-title="凌乱之风" width="20" height="20" class="avatar" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/>&nbsp;凌乱之风</a></span><span class="post-included-in">&nbsp;收录于 <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category" title="分类 - 机器学习"><i class="fa-regular fa-folder fa-fw" aria-hidden="true"></i> 机器学习</a></span></div><div class="post-meta-line"><span title="发布于 2024-11-10 14:07:00"><i class="fa-solid fa-calendar-days fa-fw me-1" aria-hidden="true"></i><time datetime="2024-11-10">2024-11-10</time></span>&nbsp;<span title="更新于 2024-11-21 09:24:39"><i class="fa-regular fa-calendar-check fa-fw me-1" aria-hidden="true"></i><time datetime="2024-11-21">2024-11-21</time></span>&nbsp;<span title="1914 字"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden="true"></i>约 2000 字</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden="true"></i>预计阅读 4 分钟</span>&nbsp;</div>
    </div><div class="details toc" id="toc-static" data-kept="false">
        <div class="details-summary toc-title">
          <span>目录</span>
          <span><i class="details-icon fa-solid fa-angle-right" aria-hidden="true"></i></span>
        </div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#模型">模型</a>
      <ul>
        <li><a href="#神经元">神经元</a></li>
        <li><a href="#损失函数">损失函数</a></li>
        <li><a href="#反向传播">反向传播</a>
          <ul>
            <li><a href="#四个基本公式">四个基本公式</a>
              <ul>
                <li><a href="#公式-1">公式 1</a></li>
                <li><a href="#公式-2">公式 2</a></li>
                <li><a href="#公式-3">公式 3</a></li>
                <li><a href="#公式-4">公式 4</a></li>
              </ul>
            </li>
            <li><a href="#过程">过程</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#参考">参考</a></li>
  </ul>
</nav></div>
      </div><div class="content" id="content"><h2 id="模型" class="heading-element"><span>模型</span>
  <a href="#%e6%a8%a1%e5%9e%8b" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>模型由多层感知机构成，每层有若干个神经元，第一层是输入层，最后一层是输出层。如下图所示</p>
<p><img loading="lazy" src="/image/ML/5.jpg" alt="1" srcset="/image/ML/5.jpg?size=small, /image/ML/5.jpg?size=medium 1.5x, /image/ML/5.jpg?size=large 2x" data-title="1" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></p>
<p>其中输入层表示输入数据的若干个特征 记为 $x_1, x_2, \cdots, x_n$，输出层表示分类的概率。</p>
<h3 id="神经元" class="heading-element"><span>神经元</span>
  <a href="#%e7%a5%9e%e7%bb%8f%e5%85%83" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p><img loading="lazy" src="/image/ML/6.jpg" alt="1" srcset="/image/ML/6.jpg?size=small, /image/ML/6.jpg?size=medium 1.5x, /image/ML/6.jpg?size=large 2x" data-title="1" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></p>
<p>每个节点就是一个神经元，从图中不难发现上一层的每个神经元都有一条边连向该神经元，其中边有边权 $w$</p>
<p>定义 $w ^ l_{jk}$ 为第 $l-1$ 层的第 $k$ 个神经元和第 $l$ 层的第 $j$ 个神经元连接对应的权重 ($l - 1$ 层表示他左边的层)</p>
<p>定义 $z^l_j$ 为第 $l$ 层第 $j$ 个神经元的未激活值(加权计算值)。</p>
<p>定义 $a^l_j$ 为第 $l$ 层第 $j$ 个神经元的激活值。</p>
<p>定义 $b^l_j$ 为第 $l$ 层第 $j$ 个神经元带有的偏置。</p>
<p>其中</p>
<p>$$
z_j^l = \sum\limits_k w_{jk} ^ l a_k ^ {l - 1} + b_j ^ l \\
a_j^l=\sigma(z_j^l)
$$</p>
<p>$\sigma(x)$ 代表 sigmoid 函数，$k$ 下标求和范围为 $l$ 层神经元个数。</p>
<p>直观来讲就是该神经元的值是上一层每个神经元的值乘以到他的边权，累加起来再加上一个该神经元带的偏置，最后套一个 sigmoid 函数。</p>
<p>那么为什么要套 sigmoid？因为线性组合如果叠加在一起，那么始终可以用一个式子来表达，就用不着多层网络了，所以要引入一个非线性的复合，并且，sigmoid 可以让数据归一化，始终在 $(0, 1)$ 之间。当然 ReLU 也是可以的。</p>
<h3 id="损失函数" class="heading-element"><span>损失函数</span>
  <a href="#%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>定义 $y_j$ 表示输出层第 $j$ 个输出的真实值。</p>
<p>考虑用 MSE (均方误差) 来作为损失函数 $C$
$$
C = \frac{1}{2}\sum_{k}(y_k - a_k ^ l) ^ 2
$$</p>
<h3 id="反向传播" class="heading-element"><span>反向传播</span>
  <a href="#%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>现在考虑最小化损失函数，一般来说都是梯度下降，但是我们需要调整整个网络中的 $w, b$ 来使损失函数最小化，这样不好计算。</p>
<p>我们知道，训练过程就是要让模型的预测 $a^l_j$ 越接近真实值 $y_j$ 越好。那么 $a^l_j$ 跟什么有关呢？根据样本的真实值 $y_j$，可以计算 $a^l_j$ 和 $y_j$ 的误差，计算出误差之后，我们肯定知道要增大还是减小 $a^l_j$ 才能让模型的预测更好。而我们能够改变的量只有：第 $l - 1$ 层和第 $l$ 层之间的每个权重 $w^l_{jk}$，偏置项 $b_j^l$，或者是第 $l-1$ 层的激活函数的输出值 $a^{l-1}_k$，但是 $a_k^{l-1}$ 并无法直接改变，它是由更前面的权重和偏置项的值决定的。当我们从后往前根据预测的误差，考虑要如何修改每一层的权重和偏置项的时候，就是在做反向传播。</p>
<p>上述过程解释了 $a_j^l$ 想要如何调整模型的权重和偏置项。当然，我们还需要考虑输出层中除了$a_j^l$ 以外的神经元的“意见”。他们各自对如何改变模型的权重和偏置项的“意见”并不一定相同。最后，我们需要考虑输出层中所有神经元的意见来更新模型的权重和偏差。</p>
<h4 id="四个基本公式" class="heading-element"><span>四个基本公式</span>
  <a href="#%e5%9b%9b%e4%b8%aa%e5%9f%ba%e6%9c%ac%e5%85%ac%e5%bc%8f" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h4><p>我们希望能得到任意的 $\dfrac{\partial C}{\partial w_{jk}}, \dfrac{\partial C}{\partial b^l_j}$</p>
<p>在此之前，我们先定义几个东西。</p>
<h5 id="公式-1" class="heading-element"><span>公式 1</span>
  <a href="#%e5%85%ac%e5%bc%8f-1" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h5><p>定义 $\delta^l_j \equiv \dfrac{\partial C}{\partial z^l_j}$
那么有</p>
<p>$$
\begin{aligned}
\delta_j^l &amp;= \frac{\partial C}{\partial z_j^l} \\
&amp;= \frac{\partial C}{\partial a_j^l} \frac{\partial a_j^l}{\partial z_j^l} \\
&amp;= \frac{\partial C}{\partial a_j^l} \frac{\partial \sigma(z_j^l)}{\partial z_j^l}  \\
&amp;= \frac{\partial C}{\partial a_j^l}\sigma ' (z_j^l)
\end{aligned}
$$</p>
<p>然后 $\dfrac{\partial C}{\partial a^l_j} = (y_j - a^l_j)$，所以 $\delta_j^l = (y_j - a^l_j)\sigma ' (z_j^l)$</p>
<p>那么 $l$ 层的 $\delta$ 用矩阵表示：</p>
<p>$$
\delta ^ l = \begin{bmatrix}
\frac{\partial C}{\partial a_1^l}\sigma ' (z_1^l) \\
\frac{\partial C}{\partial a_2^l}\sigma ' (z_2^l) \\
\vdots \\
\frac{\partial C}{\partial a_k^l}\sigma ' (z_k^l) \\
\end{bmatrix} = \begin{bmatrix}
\frac{\partial C}{\partial a_1^l} \\
\frac{\partial C}{\partial a_2^l} \\
\vdots \\
\frac{\partial C}{\partial a_k^l} \\
\end{bmatrix} \odot \begin{bmatrix}
\sigma ' (z_1^l) \\
\sigma ' (z_2^l) \\
\vdots \\
\sigma ' (z_k^l) \\
\end{bmatrix} = \nabla C_{a^l} \odot \sigma ' (z^l)
$$</p>
<p>其中 $\odot$ 表示按元素 (element-wise) 乘。</p>
<h5 id="公式-2" class="heading-element"><span>公式 2</span>
  <a href="#%e5%85%ac%e5%bc%8f-2" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h5><p>继续对于 $l - 1$ 层进行推导。</p>
<p>$$
\begin{aligned}
\delta_j^{l - 1} &amp;= \frac{\partial C}{\partial z_j^{l - 1}} \\
&amp;= \frac{\partial C}{\partial a_j^{l - 1}} \frac{\partial a_j^{l - 1}}{\partial z_j^{l - 1}} \\
&amp;= \frac{\partial C}{\partial a_j^{l - 1}} \frac{\partial \sigma(z_j^{l - 1})}{\partial z_j^{l - 1}}  \\
&amp;= \frac{\partial C}{\partial a_j^{l - 1}} \sigma ' (z_j^{l - 1})
\end{aligned}
$$</p>
<p>发现此时 $\dfrac{\partial C}{\partial a_j^{l - 1}}$ 不好求了，但我们知道 $a_j^{l - 1}$ 和 $z_j^l$ 都有关。</p>
<p>拿 $a^{l - 1}_1$ 举例子，如下图</p>
<p><img loading="lazy" src="/image/ML/7.jpg" alt="1" srcset="/image/ML/7.jpg?size=small, /image/ML/7.jpg?size=medium 1.5x, /image/ML/7.jpg?size=large 2x" data-title="1" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></p>
<p>所以我们可以先把 $C$ 看成 $z^l_1, z^l_2, \cdots, z^l_k$ 的复合函数。</p>
<p>$$
\begin{aligned}
\frac{\partial C}{\partial a_1^{l - 1}} &amp;= \frac{\partial C(z^l_1, z^l_2, \cdots, z^l_k)}{\partial a_1^{l - 1}} \\
&amp;= \sum_k \frac{\partial C}{\partial z^l_k} \frac{\partial z^l_k}{\partial a_1^{l - 1}}
\end{aligned}
$$</p>
<p>由于 $z_j^l = \sum\limits_k w_{jk} ^ l a_k ^ {l - 1} + b_j ^ l$，所以 $\dfrac{\partial z^l_k}{\partial a_1^{l - 1}} = w_{k1} ^ l$</p>
<p>又根据公式 1 的定义 $\delta^l_j \equiv \dfrac{\partial C}{\partial z^l_j}$，将两个式子带入上述求和公式得：</p>
<p>$$
\sum_k \frac{\partial C}{\partial z^l_k} \frac{\partial z^l_k}{\partial a_1^{l - 1}} = \sum_k w^l_{k1}\delta_k^l
$$</p>
<p>同理，对于其他的 $a^{l - 1}_{j}$，都有：</p>
<p>$$
\frac{\partial C}{\partial a_j^{l - 1}} = \sum_k w^l_{kj}\delta_k^l
$$</p>
<p>所以说，$\delta_j^{l - 1} = \dfrac{\partial C}{\partial a_j^{l - 1}} \sigma ' (z_j^{l - 1}) = \left(\sum\limits_k w^l_{kj}\delta_k^l \right) \times \sigma ' (z_j^{l - 1})$</p>
<p>推广到矩阵形式，即对 $l$ 层所有 $\delta ^ l$ (层数下标先平移一层)：</p>
<p>$$
\delta ^ l =
\begin{bmatrix}
\left(\sum\limits_k w^{l + 1}_{k1} \delta^{l + 1}_k \right) \times \sigma ' (z_1^l) \\
\left(\sum\limits_k w^{l + 1}_{k2} \delta^{l + 1}_k \right) \times \sigma ' (z_2^l) \\
\vdots \\
\left(\sum\limits_k w^{l + 1}_{kn} \delta^{l + 1}_k \right) \times \sigma ' (z_n^l) \\
\end{bmatrix}
= ((w^{l+1})^\top \delta^{l+1})\odot \sigma ' (z^l)
$$</p>
<h5 id="公式-3" class="heading-element"><span>公式 3</span>
  <a href="#%e5%85%ac%e5%bc%8f-3" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h5><p>好了现在终于可以解决 $w, b$ 的偏导问题了</p>
<p>$$
\begin{aligned}
\frac{\partial C}{\partial b^l_j} &amp;= \frac{\partial C}{\partial z^l_j} \frac{\partial z^l_j}{\partial b^l_j} \\
&amp;= \frac{\partial C}{\partial z^l_j} \\
&amp;= \delta^l_j
\end{aligned}
$$</p>
<p>由于 $z_j^l = \sum\limits_k w_{jk} ^ l a_k ^ {l - 1} + b_j ^ l$，所以 $\dfrac{\partial z^l_j}{\partial b^l_j} = 1$</p>
<h5 id="公式-4" class="heading-element"><span>公式 4</span>
  <a href="#%e5%85%ac%e5%bc%8f-4" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h5><p>$$
\begin{aligned}
\frac{\partial C}{\partial w_{jk}^l}&amp;=\frac{\partial C}{\partial z^l_j}\frac{\partial z^l_j}{\partial w_{jk}^l} \\
&amp;=\frac{\partial C}{\partial z^l_j} a_k^{l-1} \\
&amp;=\delta_j^l a_k^{l-1}
\end{aligned}
$$</p>
<p>由于 $z_j^l = \sum\limits_k w_{jk} ^ l a_k ^ {l - 1} + b_j ^ l$，所以 $\dfrac{\partial z^l_j}{\partial w^l_{jk}} = a^{l - 1}_k$</p>
<h4 id="过程" class="heading-element"><span>过程</span>
  <a href="#%e8%bf%87%e7%a8%8b" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h4><p>至此我们基于 4 个公式，给出反向传播的流程：</p>
<p>首先前向传播，计算每个 $z_j^l$，$a_j^l$，根据公式 1 计算输出层的 $\delta^l$</p>
<p>然后从后往前：</p>
<ol>
<li>根据公式 2 计算每一层的梯度向量 $\delta^l$，注意我们总是可以根据 $\delta^{l+1}$ 计算出 $\delta^l$</li>
<li>根据公式 3 可以计算出每个偏置项 $b^l_j$ 的梯度 $\delta^l_j$</li>
<li>根据公式 4 可以计算出每个权重 $w^l_{jk}$ 的梯度 $\delta_j^la_k^{l-1}$</li>
</ol>
<p>上面这个过程也回答了为什么反向传播是一个高效的算法这个问题:</p>
<ol>
<li>根据公式 2，计算第 $l$ 层的梯度向量 $\delta^l$ 的时候 $\delta^{l+1}$ 已经算好了，不用从头从输出层开始推导。</li>
<li>根据公式 3 和公式 4，直接算出了损失函数对当前层权重和偏置项的梯度，而不是其他什么中间的梯度结果。</li>
</ol>
<h2 id="参考" class="heading-element"><span>参考</span>
  <a href="#%e5%8f%82%e8%80%83" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p><a href="https://martinlwx.github.io/zh-cn/backpropagation-tutorial/"target="_blank" rel="external nofollow noopener noreferrer">https://martinlwx.github.io/zh-cn/backpropagation-tutorial/</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/683499770"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/683499770</a></p>
<p><a href="https://playground.tensorflow.org/"target="_blank" rel="external nofollow noopener noreferrer">https://playground.tensorflow.org/</a></p>
</div><div class="post-footer" id="post-footer">
  <div class="post-info">
    <div class="post-info-line">
      <div class="post-info-mod">
        <span title="更新于 2024-11-21 09:24:39">更新于 2024-11-21&nbsp;</span>
      </div></div><div class="post-info-line">
        <div class="post-info-md"><span><a href="/posts/%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.md" title="阅读原始文档" class="link-to-markdown">阅读原始文档</a></span></div>
        <div class="post-info-share">
          <span></span>
        </div>
      </div></div>

  <div class="post-info-more">
    <section class="post-tags"><i class="fa-solid fa-tags fa-fw me-1" aria-hidden="true"></i><a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="post-tag" title="标签 - 神经网络">神经网络</a></section>
    <section>
      <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
    </section>
  </div><div class="post-nav"><a href="/posts/%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F-s14-%E6%80%BB%E5%86%B3%E8%B5%9B/" class="post-nav-item" rel="prev" title="2024 英雄联盟 S14 全球总决赛 观赛感悟"><i class="fa-solid fa-angle-left fa-fw" aria-hidden="true"></i>2024 英雄联盟 S14 全球总决赛 观赛感悟</a><a href="/posts/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" class="post-nav-item" rel="next" title="支持向量机 (SVM)">支持向量机 (SVM)<i class="fa-solid fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article>

  <aside class="toc" id="toc-auto" aria-label="目录"><h2 class="toc-title">目录&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden="true"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">由 <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.139.0">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.3.15">FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2024</span><span class="author" itemprop="copyrightHolder">
              <a href="https://github.com/messywind"target="_blank" rel="external nofollow noopener noreferrer">凌乱之风</a></span></div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="回到顶部"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric d-none">0%</span>
        </div></div><div id="mask"></div><noscript>
    <div class="noscript-warning">该网站在启用 JavaScript 的情况下效果最佳。</div>
  </noscript>
</div><link rel="preload" href="/lib/katex/katex.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/katex/katex.min.css"></noscript><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script src="/lib/autocomplete/autocomplete.min.js" defer></script><script src="/lib/fuse/fuse.min.js" defer></script><script src="/lib/katex/katex.min.js" defer></script><script src="/lib/katex/auto-render.min.js" defer></script><script src="/lib/katex/copy-tex.min.js" defer></script><script src="/lib/katex/mhchem.min.js" defer></script><script src="/lib/cookieconsent/cookieconsent.min.js" defer></script><script>window.config={"code":{"copyTitle":"复制到剪贴板","editLockTitle":"锁定可编辑代码块","editUnLockTitle":"解锁可编辑代码块","editable":true,"maxShownLines":11},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验。"},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"distance":100,"findAllMatches":false,"fuseIndexURL":"/search.json","highlightTag":"em","ignoreFieldNorm":false,"ignoreLocation":false,"isCaseSensitive":false,"location":0,"maxResultLength":10,"minMatchCharLength":2,"noResultsFound":"没有找到结果","snippetLength":30,"threshold":0.3,"type":"fuse","useExtendedSearch":false},"version":"v0.3.15"};</script><script src="/js/theme.min.js" defer></script><script src="/js/custom.min.js" defer></script></body>
</html>
